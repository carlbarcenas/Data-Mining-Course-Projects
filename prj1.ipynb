{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jRbuIIjtMMFj"
   },
   "source": [
    "# COSC 4610/5610 Project 1 (spring 2022)\n",
    "\n",
    "**Authors**: Carl Barcenas\n",
    "\n",
    "**Emails**: carlanthony.barcenas@marquette.edu\n",
    "\n",
    "**Submission.** Please insert your names and emails above, save your code in this notebook, and explain what you are doing along with your findings in text cells. You can think of it as a technical report with code. Before submission, please use `Kernel -> Restart & Run All` in the Jupyter menu to verify your code is runnable and save all outputs. Afterwards, you can either upload your raw notebook (`prj1.ipynb`) or an exported PDF version. \n",
    "\n",
    "\n",
    "In this project, we will practice with data cleaning and transformation methods on the California house sales data and check their effects on the price prediction model. The model training and the evaluation code will be given. Your job is to try different data pre-processing methods to obtain the best root mean squared logarithmic error (RMSLE) on the test dataset.\n",
    "\n",
    "## Set up the environment\n",
    "We will use AutoGluon (https://auto.gluon.ai/) to simplify the modeling step. However, AutoGluon works only on Python 3.7 so far. It also only works on Linux and Mac. Thus, it's necessary to set up the environment first. \n",
    "\n",
    "### Python 3.7 on Ubuntu (and WSL)\n",
    "If you need to install Python 3.7 in Ubuntu (and WSL), you can follow the steps\n",
    "1. Start by updating the packages list and installing the prerequisites:\n",
    "\n",
    "`sudo apt update`\n",
    "\n",
    "`sudo apt install software-properties-common`\n",
    "\n",
    "2. Next, add the deadsnakes PPA to your sources list:\n",
    "\n",
    "`sudo add-apt-repository ppa:deadsnakes/ppa`\n",
    "\n",
    "When prompted press Enter to continue:\n",
    "\n",
    "Press [ENTER] to continue or Ctrl-c to cancel adding it.Copy\n",
    "\n",
    "3. Once the repository is enabled, install Python 3.7 with:\n",
    "\n",
    "`sudo apt install python3.7`\n",
    "\n",
    "If you are using Windows, you want to set up the WSL first (https://docs.microsoft.com/en-us/windows/wsl/install), install Python 3.7, and then run the jupyter server with the command `jupyter notebook --no-browser`. Virtualenv is also recommended if the default Python version is not 3.7. You can then access the server in your Windows browser with prompted URL (check the line after \"Or copy and paste one of these URLs\"). \n",
    "\n",
    "### Python 3.7 on Mac\n",
    "Run the command `brew install python@3.7`. The binary should be on /usr/local/opt/python@3.7/bin/python3.7\n",
    "\n",
    "\n",
    "### Virtualenv for multiple versions of Python\n",
    "If you are using Linux (or WSL) and Mac but not on Python 3.7 (e.g., your system has a higher version Python), the following method allows you to set up an isolated virtual environment, which does not interfere with your existing Python setups. \n",
    "1. download and install Python 3.7. Get the path to the specific Python3 binary. For example, in my system, it's installed at /usr/local/opt/python@3.7/bin/python3\n",
    "\n",
    "2. run `pip3 install virtualenv` to install the tool virtualenv\n",
    "\n",
    "3. run `virtualenv -p path_to_your_python3.7_binary py37` to create the virtual environment named py37. You will see a subdirectory named py37 is created under the current directory.\n",
    "\n",
    "4. run `source py37/bin/activate` to activate the py37 environment. You will see (py37) shows up in your command line prompt. You can run `deactivate` later to exit the virtual environment\n",
    "\n",
    "5. after py37 is activiated, install the necessary packages: `pip3 install notebook numpy pandas autogluon mxnet`\n",
    "\n",
    "6. run `jupyter notebook` and you are ready to use the python 3.7 environment and the autogluon package.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Prepare Data \n",
    "\n",
    "Download the data from http://www.cs.mu.edu/~keke/dm/data/house_sales.ftr. Note that we use the [`feather` format](https://arrow.apache.org/docs/python/feather.html), which is faster to read than CSV but uses more disk space. \n",
    "The following code needs at least 2GB memory. If using a local runtime, please make sure your machine has enough memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T21:19:22.818413Z",
     "start_time": "2021-09-22T21:19:18.899437Z"
    },
    "id": "YpsTjkMaMMFk"
   },
   "outputs": [],
   "source": [
    "# If the pacakges are not installed, run the following line once to install. You may need to restart your runtime afterwards:\n",
    "#!pip3 install numpy pandas autogluon mxnet --upgrade  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_feather('house_sales.ftr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlvsGd0AMMFl"
   },
   "source": [
    "We select a few columns to demonstrate. You need to select more columns to make your model more accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T21:19:22.837345Z",
     "start_time": "2021-09-22T21:19:22.821365Z"
    },
    "id": "vMIZGUkiMMFl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sold Price    object\n",
       "Sold On       object\n",
       "Type          object\n",
       "Year built    object\n",
       "Bedrooms      object\n",
       "Bathrooms     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data[['Sold Price', 'Sold On', 'Type', 'Year built', 'Bedrooms', 'Bathrooms']].copy()\n",
    "# uncomment the below line to save memory\n",
    "# del data\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We copy the code from EDA to convert `Sold Price` to numerical values, which is our prediction target. We also remove examples whose prices are too high or too low. For more examples, you can revisit the notebook https://www.cs.mu.edu/~keke/dm/house.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T21:19:23.275937Z",
     "start_time": "2021-09-22T21:19:22.838990Z"
    },
    "id": "QEtKW8aZMMFl"
   },
   "outputs": [],
   "source": [
    "\n",
    "c = 'Sold Price'\n",
    "if c in df.select_dtypes('object').columns:\n",
    "    df.loc[:,c] = np.log10(\n",
    "            pd.to_numeric(df[c].replace(r'[$,-]', '', regex=True)) + 1)\n",
    "    \n",
    "df = df[(df['Sold Price'] >= 4 ) & (df['Sold Price'] <= 8 )] # prices between 10^4 and 10^8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwS6XYWAMMFm"
   },
   "source": [
    "We use the house sales between 2021-2-15 and 2021-3-1 as our test data. You can use any example before 2021-2-15 for training, but not after. In other words, we pretend we are launching our model on 2021-2-15 and testing it for 2 weeks. Here we only use sales in 2021 for fast training, but you can use more to improve accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T21:19:57.603573Z",
     "start_time": "2021-09-22T21:19:57.487636Z"
    },
    "id": "8HA0DTInMMFm"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24872, 6), (11510, 6))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_start, test_end = pd.Timestamp(2021, 2, 15), pd.Timestamp(2021, 3, 1)\n",
    "train_start = pd.Timestamp(2021, 1, 1) # you can change the start time stamp to include more training \n",
    "df['Sold On'] = pd.to_datetime(df['Sold On'], errors='coerce')\n",
    "train = df[(df['Sold On'] >= train_start) & (df['Sold On'] < test_start)]\n",
    "test = df[(df['Sold On'] >= test_start) & (df['Sold On'] < test_end)]\n",
    "train.shape, test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AH-Gx95nMMFn"
   },
   "source": [
    "Define our evaluation metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T21:19:58.917830Z",
     "start_time": "2021-09-22T21:19:58.915173Z"
    },
    "id": "FP0f3vqNMMFn"
   },
   "outputs": [],
   "source": [
    "def rmsle(y_hat, y):\n",
    "    # we already used log prices before, so we only need to compute RMSE\n",
    "    return sum((y_hat - y)**2 / len(y))**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXFkQrUUMMFn"
   },
   "source": [
    "## Regression Baseline\n",
    "\n",
    "We compute the baseline model with a gradient boosting regressor (GBM). You are welcome to try other models to achieve the best result. Available options include ‘GBM’ (LightGBM), ‘CAT’ (CatBoost), ‘XGB’ (XGBoost), ‘RF’ (random forest), ‘XT’ (extremely randomized trees), ‘KNN’ (k-nearest neighbors), ‘LR’ (linear regression), ‘NN’ (neural network with MXNet backend), ‘FASTAI’ (neural network with FastAI backend). However, we recommend that you reuse the following training code so that you can focus on data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-22T21:22:15.382886Z",
     "start_time": "2021-09-22T21:20:10.070746Z"
    },
    "id": "JPc8RXxJMMFn",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220517_030223\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20220517_030223\\\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.9.12\n",
      "Operating System:   Windows\n",
      "Train Data Rows:    24872\n",
      "Train Data Columns: 5\n",
      "Label Column: Sold Price\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (7.546542675816042, 4.000043427276863, 5.75084, 0.39719)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4016.99 MB\n",
      "\tTrain Data (Original)  Memory Usage: 6.15 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Bedrooms']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 36\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 36 to 5 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('datetime', [])                   : 1 | ['Sold On']\n",
      "\t\t('object', [])                     : 2 | ['Type', 'Bathrooms']\n",
      "\t\t('object', ['datetime_as_object']) : 1 | ['Year built']\n",
      "\t\t('object', ['text'])               : 1 | ['Bedrooms']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :  2 | ['Type', 'Bathrooms']\n",
      "\t\t('category', ['text_as_category'])  :  1 | ['Bedrooms']\n",
      "\t\t('int', ['binned', 'text_special']) : 10 | ['Bedrooms.char_count', 'Bedrooms.word_count', 'Bedrooms.capital_ratio', 'Bedrooms.lower_ratio', 'Bedrooms.digit_ratio', ...]\n",
      "\t\t('int', ['datetime_as_int'])        :  8 | ['Sold On', 'Sold On.month', 'Sold On.day', 'Sold On.dayofweek', 'Year built', ...]\n",
      "\t\t('int', ['text_ngram'])             :  6 | ['__nlp__.bedroom', '__nlp__.floor', '__nlp__.ground', '__nlp__.ground floor', '__nlp__.master', ...]\n",
      "\t1.0s = Fit runtime\n",
      "\t5 features in original data used to generate 27 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.62 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 22384, Val Rows: 2488\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.2891\t = Validation score   (root_mean_squared_error)\n",
      "\t3.82s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.2891\t = Validation score   (root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.14s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220517_030223\\\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "label = 'Sold Price'    \n",
    "predictor = TabularPredictor(label=label).fit(train, hyperparameters={'GBM':{}})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1c0cM3QMMFo"
   },
   "source": [
    "Next, we compute the importance of each feature, along with several other metrics. It loooks like the `Sold On` feature is not very useful, likely because the houses in the test data were all sold late. You can choose to either remove such a feature, or find a way to extract a more useful presentation from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 5 features using 1000 rows with 3 shuffle sets...\n",
      "\t1.3s\t= Expected runtime (0.43s per shuffle set)\n",
      "\t0.72s\t= Actual runtime (Completed 3 of 3 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>0.097894</td>\n",
       "      <td>0.008260</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>3</td>\n",
       "      <td>0.145224</td>\n",
       "      <td>0.050564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bathrooms</th>\n",
       "      <td>0.091230</td>\n",
       "      <td>0.010910</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>3</td>\n",
       "      <td>0.153743</td>\n",
       "      <td>0.028716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year built</th>\n",
       "      <td>0.059341</td>\n",
       "      <td>0.010620</td>\n",
       "      <td>0.005254</td>\n",
       "      <td>3</td>\n",
       "      <td>0.120194</td>\n",
       "      <td>-0.001512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bedrooms</th>\n",
       "      <td>0.012770</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.013809</td>\n",
       "      <td>3</td>\n",
       "      <td>0.034282</td>\n",
       "      <td>-0.008741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sold On</th>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.324912</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005695</td>\n",
       "      <td>-0.005119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            importance    stddev   p_value  n  p99_high   p99_low\n",
       "Type          0.097894  0.008260  0.001182  3  0.145224  0.050564\n",
       "Bathrooms     0.091230  0.010910  0.002366  3  0.153743  0.028716\n",
       "Year built    0.059341  0.010620  0.005254  3  0.120194 -0.001512\n",
       "Bedrooms      0.012770  0.003754  0.013809  3  0.034282 -0.008741\n",
       "Sold On       0.000288  0.000944  0.324912  3  0.005695 -0.005119"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiL2aZB9MMFo"
   },
   "source": [
    "Finally, let's predict and evaluate the RMSLE. The smaller the RMSLE value, the better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T18:51:18.826116Z",
     "start_time": "2021-09-21T18:51:16.913391Z"
    },
    "id": "budOt2bGMMFo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2682227238087204"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "preds = predictor.predict(test.drop(columns=[label]))\n",
    "rmsle(preds, test[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the evaluation part in a function for easier use. You may modify it as you like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(train, test):\n",
    "    from autogluon.tabular import TabularPredictor\n",
    "    label = 'Sold Price'    \n",
    "    predictor = TabularPredictor(label=label).fit(train, hyperparameters={'GBM':{}})\n",
    "    preds = predictor.predict(test.drop(columns=[label]))\n",
    "    print(rmsle(preds, test[label]))\n",
    "\n",
    "# with updated train/test datasets, call the function eval_model(train, test)\n",
    "#eval_model(train, test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-21T17:10:23.648923Z",
     "start_time": "2021-09-21T17:10:16.162130Z"
    },
    "id": "abfuZLOWMMFo"
   },
   "source": [
    "## Your Tasks\n",
    "\n",
    "Your goal is to train a model using the features in the original dataset that minimizes the RMSLE on the validation dataset. While the naïve model achieves an RMSLE of ~0.3, it is possible to achieve an RMSLE of less than 0.08 on the same dataset (extra credit: +5, if you can find a model with RMSLE <0.1 :-) ).  \n",
    "\n",
    "Complete the following tasks. \n",
    "\n",
    "1. Try more features: We only selected a small set of columns to use in training. You can add more, especially the ones we examined in EDA. You can add batches of features progressively. Report what you have done and what you have observed about the RMSLE change. \n",
    "\n",
    "2. Data type conversion: Most data columns are strings; you may need to convert them into numerical values. Describe how you convert them, and report the RMSLE change.\n",
    "\n",
    "3. Data cleaning: There are NAN and outliers sprinkled throughout the dataset. You should find ways to selectively filter and remove them. Describe what you do and report the RMSLE change.\n",
    "\n",
    "4. More examples: We only included sales made in 2021; there is a large number of examples in previous years that you can also include. You may try different strategies to include more training data. However, alway keep the house sales between 2021-2-15 and 2021-3-1 as our test data. Describe what you do and report the RMSLE change. \n",
    "\n",
    "You may reorganize the code with functions to reuse pieces of code and make your code clearer. Report any RMSLE changes (may increase or decrease after a specific experiment).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STUDENT SOLUTION SECTION\n",
    "## Evaluating the Data\n",
    "If I want to add features, I need to know what I'm working with. I want to see the possible columns I can use and other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Mvs8Kh0dDJRZ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Address</th>\n",
       "      <th>Sold Price</th>\n",
       "      <th>Sold On</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Type</th>\n",
       "      <th>Year built</th>\n",
       "      <th>Heating</th>\n",
       "      <th>Cooling</th>\n",
       "      <th>Parking</th>\n",
       "      <th>...</th>\n",
       "      <th>Well Disclosure</th>\n",
       "      <th>remodeled</th>\n",
       "      <th>DOH2</th>\n",
       "      <th>SerialX</th>\n",
       "      <th>Full Baths</th>\n",
       "      <th>Tax Legal Lot Number</th>\n",
       "      <th>Tax Legal Block Number</th>\n",
       "      <th>Tax Legal Tract Number</th>\n",
       "      <th>Building Name</th>\n",
       "      <th>Zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2080183300</td>\n",
       "      <td>11205 Monterey,</td>\n",
       "      <td>$2,000,000</td>\n",
       "      <td>01/31/20</td>\n",
       "      <td>11205 Monterey, San Martin, CA 95046 is a sing...</td>\n",
       "      <td>SingleFamily</td>\n",
       "      <td>No Data</td>\n",
       "      <td>No Data</td>\n",
       "      <td>No Data</td>\n",
       "      <td>0 spaces</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>95046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20926300</td>\n",
       "      <td>5281 Castle Rd,</td>\n",
       "      <td>$2,100,000</td>\n",
       "      <td>02/25/21</td>\n",
       "      <td>Spectacular Mountain and incredible L.A. City ...</td>\n",
       "      <td>SingleFamily</td>\n",
       "      <td>1951</td>\n",
       "      <td>Central</td>\n",
       "      <td>Central Air, Dual</td>\n",
       "      <td>Driveway, Driveway - Brick</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>91011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19595300</td>\n",
       "      <td>3581 Butcher Dr,</td>\n",
       "      <td>$1,125,000</td>\n",
       "      <td>11/06/19</td>\n",
       "      <td>Eichler Style home! with Santa Clara High! in ...</td>\n",
       "      <td>SingleFamily</td>\n",
       "      <td>1954</td>\n",
       "      <td>Central Forced Air - Gas</td>\n",
       "      <td>Central AC</td>\n",
       "      <td>Garage, Garage - Attached, Covered</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>95051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300472200</td>\n",
       "      <td>2021 N Milpitas Blvd,</td>\n",
       "      <td>$36,250,000</td>\n",
       "      <td>10/02/20</td>\n",
       "      <td>2021 N Milpitas Blvd, Milpitas, CA 95035 is a ...</td>\n",
       "      <td>Apartment</td>\n",
       "      <td>1989</td>\n",
       "      <td>Other</td>\n",
       "      <td>No Data</td>\n",
       "      <td>Mixed, Covered</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>95035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2074492000</td>\n",
       "      <td>LOT 4 Tool Box Spring Rd,</td>\n",
       "      <td>$140,000</td>\n",
       "      <td>10/19/20</td>\n",
       "      <td>Beautiful level lot  dotted with pine trees ro...</td>\n",
       "      <td>VacantLand</td>\n",
       "      <td>No Data</td>\n",
       "      <td>No Data</td>\n",
       "      <td>No Data</td>\n",
       "      <td>0 spaces</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>92561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164939</th>\n",
       "      <td>72555199</td>\n",
       "      <td>88 Lakeshore Ct,</td>\n",
       "      <td>$563,527</td>\n",
       "      <td>02/19/21</td>\n",
       "      <td>STUNNING LAKE VIEW AND BAY VIEW! Exquisite Res...</td>\n",
       "      <td>Condo</td>\n",
       "      <td>1991</td>\n",
       "      <td>Baseboard, Electric</td>\n",
       "      <td>None</td>\n",
       "      <td>Carport, Covered, Guest</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>94804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164940</th>\n",
       "      <td>94643599</td>\n",
       "      <td>3785 Wilshire Blvd PENTHOUSE 3,</td>\n",
       "      <td>$2,650,000</td>\n",
       "      <td>05/31/18</td>\n",
       "      <td>Arguably the best unit at Solair. This top flo...</td>\n",
       "      <td>Condo</td>\n",
       "      <td>2009</td>\n",
       "      <td>Central</td>\n",
       "      <td>Central</td>\n",
       "      <td>Covered</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>90010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164941</th>\n",
       "      <td>300479799</td>\n",
       "      <td>312 Circuit Way,</td>\n",
       "      <td>$1,357,000</td>\n",
       "      <td>11/04/19</td>\n",
       "      <td>312 Circuit Way, Mountain View, CA 94043 is a ...</td>\n",
       "      <td>Condo</td>\n",
       "      <td>2019</td>\n",
       "      <td>Other</td>\n",
       "      <td>No Data</td>\n",
       "      <td>Garage, Garage - Attached, Covered</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164942</th>\n",
       "      <td>15504399</td>\n",
       "      <td>2 Cape Breton Ct,</td>\n",
       "      <td>$1,400,000</td>\n",
       "      <td>07/23/20</td>\n",
       "      <td>Park Pacifica CHECK OUT THE VIDEO  Entering Ca...</td>\n",
       "      <td>SingleFamily</td>\n",
       "      <td>1973</td>\n",
       "      <td>Central Forced Air - Gas</td>\n",
       "      <td>None</td>\n",
       "      <td>Underground/Basement, Garage - Attached</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>94044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164943</th>\n",
       "      <td>16143099</td>\n",
       "      <td>25 Calabasas Rd,</td>\n",
       "      <td>$225,000</td>\n",
       "      <td>11/27/19</td>\n",
       "      <td>25 Calabasas Rd, Freedom, CA 95019 is a single...</td>\n",
       "      <td>SingleFamily</td>\n",
       "      <td>1949</td>\n",
       "      <td>Wall</td>\n",
       "      <td>No Data</td>\n",
       "      <td>Garage, Garage - Attached</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>95019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164944 rows × 1789 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id                          Address   Sold Price   Sold On  \\\n",
       "0       2080183300                  11205 Monterey,   $2,000,000  01/31/20   \n",
       "1         20926300                  5281 Castle Rd,   $2,100,000  02/25/21   \n",
       "2         19595300                 3581 Butcher Dr,   $1,125,000  11/06/19   \n",
       "3        300472200            2021 N Milpitas Blvd,  $36,250,000  10/02/20   \n",
       "4       2074492000        LOT 4 Tool Box Spring Rd,     $140,000  10/19/20   \n",
       "...            ...                              ...          ...       ...   \n",
       "164939    72555199                 88 Lakeshore Ct,     $563,527  02/19/21   \n",
       "164940    94643599  3785 Wilshire Blvd PENTHOUSE 3,   $2,650,000  05/31/18   \n",
       "164941   300479799                 312 Circuit Way,   $1,357,000  11/04/19   \n",
       "164942    15504399                2 Cape Breton Ct,   $1,400,000  07/23/20   \n",
       "164943    16143099                 25 Calabasas Rd,     $225,000  11/27/19   \n",
       "\n",
       "                                                  Summary          Type  \\\n",
       "0       11205 Monterey, San Martin, CA 95046 is a sing...  SingleFamily   \n",
       "1       Spectacular Mountain and incredible L.A. City ...  SingleFamily   \n",
       "2       Eichler Style home! with Santa Clara High! in ...  SingleFamily   \n",
       "3       2021 N Milpitas Blvd, Milpitas, CA 95035 is a ...     Apartment   \n",
       "4       Beautiful level lot  dotted with pine trees ro...    VacantLand   \n",
       "...                                                   ...           ...   \n",
       "164939  STUNNING LAKE VIEW AND BAY VIEW! Exquisite Res...         Condo   \n",
       "164940  Arguably the best unit at Solair. This top flo...         Condo   \n",
       "164941  312 Circuit Way, Mountain View, CA 94043 is a ...         Condo   \n",
       "164942  Park Pacifica CHECK OUT THE VIDEO  Entering Ca...  SingleFamily   \n",
       "164943  25 Calabasas Rd, Freedom, CA 95019 is a single...  SingleFamily   \n",
       "\n",
       "       Year built                   Heating            Cooling  \\\n",
       "0         No Data                   No Data            No Data   \n",
       "1            1951                   Central  Central Air, Dual   \n",
       "2            1954  Central Forced Air - Gas         Central AC   \n",
       "3            1989                     Other            No Data   \n",
       "4         No Data                   No Data            No Data   \n",
       "...           ...                       ...                ...   \n",
       "164939       1991       Baseboard, Electric               None   \n",
       "164940       2009                   Central            Central   \n",
       "164941       2019                     Other            No Data   \n",
       "164942       1973  Central Forced Air - Gas               None   \n",
       "164943       1949                      Wall            No Data   \n",
       "\n",
       "                                        Parking  ... Well Disclosure  \\\n",
       "0                                      0 spaces  ...            None   \n",
       "1                    Driveway, Driveway - Brick  ...            None   \n",
       "2            Garage, Garage - Attached, Covered  ...            None   \n",
       "3                                Mixed, Covered  ...            None   \n",
       "4                                      0 spaces  ...            None   \n",
       "...                                         ...  ...             ...   \n",
       "164939                  Carport, Covered, Guest  ...            None   \n",
       "164940                                  Covered  ...            None   \n",
       "164941       Garage, Garage - Attached, Covered  ...            None   \n",
       "164942  Underground/Basement, Garage - Attached  ...            None   \n",
       "164943                Garage, Garage - Attached  ...            None   \n",
       "\n",
       "       remodeled  DOH2 SerialX Full Baths Tax Legal Lot Number  \\\n",
       "0           None  None    None       None                 None   \n",
       "1           None  None    None       None                 None   \n",
       "2           None  None    None       None                 None   \n",
       "3           None  None    None       None                 None   \n",
       "4           None  None    None       None                 None   \n",
       "...          ...   ...     ...        ...                  ...   \n",
       "164939      None  None    None       None                 None   \n",
       "164940      None  None    None       None                 None   \n",
       "164941      None  None    None       None                 None   \n",
       "164942      None  None    None       None                 None   \n",
       "164943      None  None    None       None                 None   \n",
       "\n",
       "       Tax Legal Block Number Tax Legal Tract Number Building Name    Zip  \n",
       "0                        None                   None          None  95046  \n",
       "1                        None                   None          None  91011  \n",
       "2                        None                   None          None  95051  \n",
       "3                        None                   None          None  95035  \n",
       "4                        None                   None          None  92561  \n",
       "...                       ...                    ...           ...    ...  \n",
       "164939                   None                   None          None  94804  \n",
       "164940                   None                   None          None  90010  \n",
       "164941                   None                   None          None  94043  \n",
       "164942                   None                   None          None  94044  \n",
       "164943                   None                   None          None  95019  \n",
       "\n",
       "[164944 rows x 1789 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Placing this here so I don't have to rerun from the top.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def rmsle(y_hat, y):\n",
    "    # we already used log prices before, so we only need to compute RMSE\n",
    "    return sum((y_hat - y)**2 / len(y))**0.5\n",
    "\n",
    "def eval_model(train, test):\n",
    "    from autogluon.tabular import TabularPredictor\n",
    "    label = 'Sold Price'    \n",
    "    predictor = TabularPredictor(label=label).fit(train, hyperparameters={'GBM':{}})\n",
    "    preds = predictor.predict(test.drop(columns=[label]))\n",
    "    print(preds)\n",
    "    print(rmsle(preds, test[label]))\n",
    "\n",
    "data = pd.read_feather('house_sales.ftr')\n",
    "\n",
    "# Visualizing the data\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full column list\n",
    "#print(data.columns.tolist())\n",
    "\n",
    "#display(data['Type'])\n",
    "#display(data['Type'].value_counts())\n",
    "#data['Type'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Try Adding New Features\n",
    "In particular, I wanted to add Heating, Cooling, and Parking into the equation as I think these are reasonable things to consider when purchasing a new house/apartment that will drastically affect the cost of the housing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220517_030350\\\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20220517_030350\\\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.9.12\n",
      "Operating System:   Windows\n",
      "Train Data Rows:    24872\n",
      "Train Data Columns: 8\n",
      "Label Column: Sold Price\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (7.546542675816042, 4.000043427276863, 5.75084, 0.39719)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    3792.29 MB\n",
      "\tTrain Data (Original)  Memory Usage: 11.59 MB (0.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Bedrooms', 'Heating', 'Cooling', 'Parking']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 1145\n",
      "\t\tWarning: Due to memory constraints, ngram feature count is being reduced. Allocate more memory to maximize model quality.\n",
      "\t\tReducing Vectorizer vocab size from 1145 to 132 to avoid OOM error\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('datetime', [])                   : 1 | ['Sold On']\n",
      "\t\t('object', [])                     : 2 | ['Type', 'Bathrooms']\n",
      "\t\t('object', ['datetime_as_object']) : 1 | ['Year built']\n",
      "\t\t('object', ['text'])               : 4 | ['Bedrooms', 'Heating', 'Cooling', 'Parking']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   2 | ['Type', 'Bathrooms']\n",
      "\t\t('category', ['text_as_category'])  :   4 | ['Bedrooms', 'Heating', 'Cooling', 'Parking']\n",
      "\t\t('int', ['binned', 'text_special']) :  42 | ['Bedrooms.char_count', 'Bedrooms.word_count', 'Bedrooms.capital_ratio', 'Bedrooms.lower_ratio', 'Bedrooms.digit_ratio', ...]\n",
      "\t\t('int', ['datetime_as_int'])        :   8 | ['Sold On', 'Sold On.month', 'Sold On.day', 'Sold On.dayofweek', 'Year built', ...]\n",
      "\t\t('int', ['text_ngram'])             : 133 | ['__nlp__.ac', '__nlp__.access', '__nlp__.access driveway', '__nlp__.air', '__nlp__.air ceiling', ...]\n",
      "\t3.1s = Fit runtime\n",
      "\t8 features in original data used to generate 189 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 8.88 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 3.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 22384, Val Rows: 2488\n",
      "Fitting 1 L1 models ...\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.2664\t = Validation score   (root_mean_squared_error)\n",
      "\t2.51s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.2664\t = Validation score   (root_mean_squared_error)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.96s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220517_030350\\\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1         6.165126\n",
      "5         5.895925\n",
      "40        6.012253\n",
      "53        5.208252\n",
      "58        5.954611\n",
      "            ...   \n",
      "164894    6.080437\n",
      "164897    6.006753\n",
      "164920    6.353038\n",
      "164932    5.572160\n",
      "164939    5.669645\n",
      "Name: Sold Price, Length: 11510, dtype: float32\n",
      "0.24332273066046678\n"
     ]
    }
   ],
   "source": [
    "# Redefine df\n",
    "df = data[['Sold Price', 'Sold On', 'Type', 'Year built', 'Bedrooms', 'Bathrooms', \n",
    "           'Heating', 'Cooling', 'Parking']].copy()\n",
    "\n",
    "# Establish prediction target and Convert sold price to numerical data.\n",
    "c = 'Sold Price'\n",
    "if c in df.select_dtypes('object').columns:\n",
    "    df.loc[:,c] = np.log10(\n",
    "            pd.to_numeric(df[c].replace(r'[$,-]', '', regex=True)) + 1)\n",
    "\n",
    "# Removing outliers in sold price\n",
    "df = df[(df['Sold Price'] >= 4 ) & (df['Sold Price'] <= 8 )] # prices between 10^4 and 10^8\n",
    "\n",
    "# Get train, test sets\n",
    "test_start, test_end = pd.Timestamp(2021, 2, 15), pd.Timestamp(2021, 3, 1)\n",
    "train_start = pd.Timestamp(2021, 1, 1) # you can change the start time stamp to include more training \n",
    "df['Sold On'] = pd.to_datetime(df['Sold On'], errors='coerce')\n",
    "train = df[(df['Sold On'] >= train_start) & (df['Sold On'] < test_start)]\n",
    "test = df[(df['Sold On'] >= test_start) & (df['Sold On'] < test_end)]\n",
    "train.shape, test.shape\n",
    "\n",
    "# Evaluate Model\n",
    "eval_model(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "These features in provided data are not utilized by the predictor and will be ignored: ['Heating', 'Cooling', 'Parking']\n",
      "Computing feature importance via permutation shuffling for 5 features using 1000 rows with 3 shuffle sets...\n",
      "\t1.5s\t= Expected runtime (0.5s per shuffle set)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1         6.031573\n",
      "5         5.873736\n",
      "40        5.777894\n",
      "53        5.065905\n",
      "58        5.881350\n",
      "            ...   \n",
      "164894    6.175815\n",
      "164897    5.858469\n",
      "164920    6.214445\n",
      "164932    5.671451\n",
      "164939    5.663757\n",
      "Name: Sold Price, Length: 11510, dtype: float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.85s\t= Actual runtime (Completed 3 of 3 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>0.097894</td>\n",
       "      <td>0.008260</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>3</td>\n",
       "      <td>0.145224</td>\n",
       "      <td>0.050564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bathrooms</th>\n",
       "      <td>0.091230</td>\n",
       "      <td>0.010910</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>3</td>\n",
       "      <td>0.153743</td>\n",
       "      <td>0.028716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year built</th>\n",
       "      <td>0.059341</td>\n",
       "      <td>0.010620</td>\n",
       "      <td>0.005254</td>\n",
       "      <td>3</td>\n",
       "      <td>0.120194</td>\n",
       "      <td>-0.001512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bedrooms</th>\n",
       "      <td>0.012770</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.013809</td>\n",
       "      <td>3</td>\n",
       "      <td>0.034282</td>\n",
       "      <td>-0.008741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sold On</th>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.324912</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005695</td>\n",
       "      <td>-0.005119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            importance    stddev   p_value  n  p99_high   p99_low\n",
       "Type          0.097894  0.008260  0.001182  3  0.145224  0.050564\n",
       "Bathrooms     0.091230  0.010910  0.002366  3  0.153743  0.028716\n",
       "Year built    0.059341  0.010620  0.005254  3  0.120194 -0.001512\n",
       "Bedrooms      0.012770  0.003754  0.013809  3  0.034282 -0.008741\n",
       "Sold On       0.000288  0.000944  0.324912  3  0.005695 -0.005119"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(preds)\n",
    "\n",
    "# Check the importance of the new column additions.\n",
    "predictor.feature_importance(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sold Price</th>\n",
       "      <th>Sold On</th>\n",
       "      <th>Type</th>\n",
       "      <th>Year built</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Heating</th>\n",
       "      <th>Cooling</th>\n",
       "      <th>Parking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.322220</td>\n",
       "      <td>2021-02-25</td>\n",
       "      <td>SingleFamily</td>\n",
       "      <td>1951</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Central</td>\n",
       "      <td>Central Air, Dual</td>\n",
       "      <td>Driveway, Driveway - Brick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.114278</td>\n",
       "      <td>2021-02-24</td>\n",
       "      <td>Townhouse</td>\n",
       "      <td>1966</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Central</td>\n",
       "      <td>None</td>\n",
       "      <td>Garage - Attached</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6.210854</td>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>SingleFamily</td>\n",
       "      <td>1958</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Natural Gas, Fireplace(s), Forced Air</td>\n",
       "      <td>None</td>\n",
       "      <td>Driveway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4.562305</td>\n",
       "      <td>2021-02-25</td>\n",
       "      <td>MobileManufactured</td>\n",
       "      <td>1975</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Heat Pump</td>\n",
       "      <td>Heat Pump</td>\n",
       "      <td>Attached Carport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>5.966142</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>SingleFamily</td>\n",
       "      <td>1977</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Natural Gas, Central</td>\n",
       "      <td>Central Air</td>\n",
       "      <td>Driveway, Concrete, Garage, Garage - Two Door</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164894</th>\n",
       "      <td>6.076641</td>\n",
       "      <td>2021-02-19</td>\n",
       "      <td>SingleFamily</td>\n",
       "      <td>1995</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Central</td>\n",
       "      <td>Central Air</td>\n",
       "      <td>Garage - Attached</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164897</th>\n",
       "      <td>5.937017</td>\n",
       "      <td>2021-02-18</td>\n",
       "      <td>SingleFamily</td>\n",
       "      <td>1941</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Central</td>\n",
       "      <td>No Data</td>\n",
       "      <td>Concrete, RV Access/Parking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164920</th>\n",
       "      <td>6.359625</td>\n",
       "      <td>2021-02-23</td>\n",
       "      <td>SingleFamily</td>\n",
       "      <td>1985</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Central</td>\n",
       "      <td>Central Air</td>\n",
       "      <td>Direct Access, Driveway, Concrete, Driveway Up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164932</th>\n",
       "      <td>5.447160</td>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>Condo</td>\n",
       "      <td>1993</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Central</td>\n",
       "      <td>Central Air</td>\n",
       "      <td>Parking Space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164939</th>\n",
       "      <td>5.750915</td>\n",
       "      <td>2021-02-19</td>\n",
       "      <td>Condo</td>\n",
       "      <td>1991</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Baseboard, Electric</td>\n",
       "      <td>None</td>\n",
       "      <td>Carport, Covered, Guest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11510 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sold Price    Sold On                Type Year built Bedrooms  \\\n",
       "1         6.322220 2021-02-25        SingleFamily       1951        3   \n",
       "5         6.114278 2021-02-24           Townhouse       1966        3   \n",
       "40        6.210854 2021-02-17        SingleFamily       1958        4   \n",
       "53        4.562305 2021-02-25  MobileManufactured       1975        2   \n",
       "58        5.966142 2021-02-18        SingleFamily       1977        3   \n",
       "...            ...        ...                 ...        ...      ...   \n",
       "164894    6.076641 2021-02-19        SingleFamily       1995        6   \n",
       "164897    5.937017 2021-02-18        SingleFamily       1941        3   \n",
       "164920    6.359625 2021-02-23        SingleFamily       1985        5   \n",
       "164932    5.447160 2021-02-17               Condo       1993        2   \n",
       "164939    5.750915 2021-02-19               Condo       1991        2   \n",
       "\n",
       "       Bathrooms                                Heating            Cooling  \\\n",
       "1            3.0                                Central  Central Air, Dual   \n",
       "5            3.0                                Central               None   \n",
       "40           2.0  Natural Gas, Fireplace(s), Forced Air               None   \n",
       "53           2.0                              Heat Pump          Heat Pump   \n",
       "58           3.0                   Natural Gas, Central        Central Air   \n",
       "...          ...                                    ...                ...   \n",
       "164894       5.0                                Central        Central Air   \n",
       "164897       2.0                                Central            No Data   \n",
       "164920       5.0                                Central        Central Air   \n",
       "164932       2.0                                Central        Central Air   \n",
       "164939       2.0                    Baseboard, Electric               None   \n",
       "\n",
       "                                                  Parking  \n",
       "1                              Driveway, Driveway - Brick  \n",
       "5                                       Garage - Attached  \n",
       "40                                               Driveway  \n",
       "53                                       Attached Carport  \n",
       "58          Driveway, Concrete, Garage, Garage - Two Door  \n",
       "...                                                   ...  \n",
       "164894                                  Garage - Attached  \n",
       "164897                        Concrete, RV Access/Parking  \n",
       "164920  Direct Access, Driveway, Concrete, Driveway Up...  \n",
       "164932                                      Parking Space  \n",
       "164939                            Carport, Covered, Guest  \n",
       "\n",
       "[11510 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Results:\n",
    "By adding new columns it appears that the RMSLE has lowered from the 0.26 to 0.24. However, it appears that the other columns added have a 0 importance as features.\n",
    "\n",
    "I believe the reason for this is because the columns have no numerical value, so following this I want to try converting some of the data.\n",
    "\n",
    "## 1.2 Adding Even More Features\n",
    "I wanted to see what happens if I add even more features. I'm simply adding more columns from `data` into `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine df\n",
    "df = data[['Sold Price', 'Sold On', 'Type', 'Year built', 'Bedrooms', 'Bathrooms', \n",
    "           'Heating', 'Cooling', 'Parking', 'Garage', 'Water', 'Summary']].copy()\n",
    "\n",
    "# Establish prediction target and Convert sold price to numerical data.\n",
    "c = 'Sold Price'\n",
    "if c in df.select_dtypes('object').columns:\n",
    "    df.loc[:,c] = np.log10(\n",
    "            pd.to_numeric(df[c].replace(r'[$,-]', '', regex=True)) + 1)\n",
    "\n",
    "# Removing outliers in sold price\n",
    "df = df[(df['Sold Price'] >= 4 ) & (df['Sold Price'] <= 8 )] # prices between 10^4 and 10^8\n",
    "\n",
    "# Get train, test sets\n",
    "test_start, test_end = pd.Timestamp(2021, 2, 15), pd.Timestamp(2021, 3, 1)\n",
    "train_start = pd.Timestamp(2021, 1, 1) # you can change the start time stamp to include more training \n",
    "df['Sold On'] = pd.to_datetime(df['Sold On'], errors='coerce')\n",
    "train = df[(df['Sold On'] >= train_start) & (df['Sold On'] < test_start)]\n",
    "test = df[(df['Sold On'] >= test_start) & (df['Sold On'] < test_end)]\n",
    "train.shape, test.shape\n",
    "\n",
    "# Evaluate Model\n",
    "eval_model(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Results:\n",
    "RMSLE Reduced from 0.24 to 0.2! Big leap from Section 1.1. However, runtime was considerably longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Converting Categorical Data to Numerical\n",
    "In this particular situation, I want to try converting the `Parking` column as I think that having no parking is a huge factor in pricing. Any parking is better than no parking. Thus, I will change '0 spaces' to 0 and anything else as 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To minimize runtime, I am going to stick with the data from section 1.1\n",
    "# Redefine df to add Heating, Cooling, Summary\n",
    "df = data[['Sold Price', 'Sold On', 'Type', 'Year built', 'Bedrooms', 'Bathrooms', \n",
    "           'Heating', 'Cooling', 'Parking']].copy()\n",
    "\n",
    "# Establish prediction target and Convert sold price to numerical data.\n",
    "c = 'Sold Price'\n",
    "if c in df.select_dtypes('object').columns:\n",
    "    df.loc[:,c] = np.log10(\n",
    "            pd.to_numeric(df[c].replace(r'[$,-]', '', regex=True)) + 1)\n",
    "\n",
    "# Removing outliers in sold price\n",
    "df = df[(df['Sold Price'] >= 4 ) & (df['Sold Price'] <= 8 )] # prices between 10^4 and 10^8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See column before changing\n",
    "print(df.loc[:, 'Parking'])\n",
    "print(\"\\n\")\n",
    "\n",
    "# Function to determine whether 0 parking spaces or not\n",
    "def parking_to_numeric(x):\n",
    "    if x=='0 spaces': return 0\n",
    "    elif x==0: return 0\n",
    "    else : return 1\n",
    "\n",
    "# Converting 'Parking' to numerical data in dataframe\n",
    "df['Parking'] = df['Parking'].apply(parking_to_numeric)\n",
    "\n",
    "# See column after changing\n",
    "print(df.loc[:, 'Parking'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train, test sets\n",
    "test_start, test_end = pd.Timestamp(2021, 2, 15), pd.Timestamp(2021, 3, 1)\n",
    "train_start = pd.Timestamp(2021, 1, 1) # you can change the start time stamp to include more training \n",
    "df['Sold On'] = pd.to_datetime(df['Sold On'], errors='coerce')\n",
    "train = df[(df['Sold On'] >= train_start) & (df['Sold On'] < test_start)]\n",
    "test = df[(df['Sold On'] >= test_start) & (df['Sold On'] < test_end)]\n",
    "train.shape, test.shape\n",
    "\n",
    "# Evaluate Model\n",
    "eval_model(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Results:\n",
    "Section 1.1 RMSLE = 0.2406 \\\n",
    "Section 2.1 RMSLE = 0.2497 \\\n",
    "Thus the RMSLE slightly increases using my encoding, not ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Converting to Numerical Data using Binary Encoding\n",
    "In this section, I want to use a library called `category_encoders` to Binary encode `Parking`. I originally wanted to use One-hot, but the encoder would result in a dataframe that overlaps the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset df to section 1.1 data\n",
    "# Redefine df to add Heating, Cooling, Summary\n",
    "df = data[['Sold Price', 'Sold On', 'Type', 'Year built', 'Bedrooms', 'Bathrooms', \n",
    "           'Heating', 'Cooling', 'Parking']].copy()\n",
    "\n",
    "# Establish prediction target and Convert sold price to numerical data.\n",
    "c = 'Sold Price'\n",
    "if c in df.select_dtypes('object').columns:\n",
    "    df.loc[:,c] = np.log10(\n",
    "            pd.to_numeric(df[c].replace(r'[$,-]', '', regex=True)) + 1)\n",
    "\n",
    "# Removing outliers in sold price\n",
    "df = df[(df['Sold Price'] >= 4 ) & (df['Sold Price'] <= 8 )] # prices between 10^4 and 10^8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment line below if not installed\n",
    "#pip install category_encoders\n",
    "import category_encoders as ce\n",
    "\n",
    "# Create object of encoder\n",
    "ce_be = ce.BinaryEncoder(cols=['Parking'])\n",
    "df = ce_be.fit_transform(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train, test sets\n",
    "test_start, test_end = pd.Timestamp(2021, 2, 15), pd.Timestamp(2021, 3, 1)\n",
    "train_start = pd.Timestamp(2021, 1, 1) # you can change the start time stamp to include more training \n",
    "df['Sold On'] = pd.to_datetime(df['Sold On'], errors='coerce')\n",
    "train = df[(df['Sold On'] >= train_start) & (df['Sold On'] < test_start)]\n",
    "test = df[(df['Sold On'] >= test_start) & (df['Sold On'] < test_end)]\n",
    "train.shape, test.shape\n",
    "\n",
    "# Evaluate Model\n",
    "eval_model(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Results:\n",
    "Section 1.1 RMSLE = 0.2406 \\\n",
    "Section 2.1 RMSLE = 0.2497 \\\n",
    "Section 2.2 RMSLE = 0.2469 \n",
    "\n",
    "Using binary encoding still results in a deprecated RMSLE.\\\n",
    "However, binary encoding still has a higher RMSLE than Section 2.1, but only \\\n",
    "by a small amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning - Impute Data with Most Frequent Method\n",
    "I was hoping to also convert `Heating` and `Cooling` to numerical data, but I noticed that it contained a lot of \"No Data\" values. Thus I am going to clean them first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset df to section 1.1 data\n",
    "# Redefine df to add Heating, Cooling, Summary\n",
    "df = data[['Sold Price', 'Sold On', 'Type', 'Year built', 'Bedrooms', 'Bathrooms', \n",
    "           'Heating', 'Cooling', 'Parking']].copy()\n",
    "\n",
    "# Establish prediction target and Convert sold price to numerical data.\n",
    "c = 'Sold Price'\n",
    "if c in df.select_dtypes('object').columns:\n",
    "    df.loc[:,c] = np.log10(\n",
    "            pd.to_numeric(df[c].replace(r'[$,-]', '', regex=True)) + 1)\n",
    "\n",
    "# Removing outliers in sold price\n",
    "df = df[(df['Sold Price'] >= 4 ) & (df['Sold Price'] <= 8 )] # prices between 10^4 and 10^8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to drop the column if more than 70% of the data is \"No Data\"\n",
    "print(\"Heating: \\n\")\n",
    "display(df['Heating'].value_counts())\n",
    "print(\"\\nCooling: \\n\")\n",
    "display(df['Cooling'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also have to check for NaN values in the dataframe\n",
    "Heating_NaN_Count = df['Heating'].isna().sum()\n",
    "Cooling_NaN_Count = df['Cooling'].isna().sum()\n",
    "\n",
    "print(\"Heating: \")\n",
    "print((Heating_NaN_Count+36222) / len(df))\n",
    "\n",
    "print(\"\\nCooling: \")\n",
    "print((Cooling_NaN_Count+51691) / len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from these results, we don't have to drop these variables because 'No Data' does not consist of 70% of values in these columns. Thus, we can try to impute using an `sklearn` function.\n",
    "\n",
    "**It is important to note that the impute strategy I'll use is `Most Frequent`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Using the imputer on Heating\n",
    "imputer = SimpleImputer(missing_values='No Data', strategy='most_frequent')\n",
    "df.Heating = imputer.fit_transform(df['Heating'].values.reshape(-1,1))[:, 0]\n",
    "\n",
    "# Using the imputer on Cooling\n",
    "imputer = SimpleImputer(missing_values='No Data', strategy='most_frequent')\n",
    "df.Cooling = imputer.fit_transform(df['Cooling'].values.reshape(-1,1))[:, 0]\n",
    "\n",
    "# Do again for 'NaN' values\n",
    "# Using the imputer on Heating\n",
    "imputer = SimpleImputer(missing_values=None, strategy='most_frequent')\n",
    "df.Heating = imputer.fit_transform(df['Heating'].values.reshape(-1,1))[:, 0]\n",
    "\n",
    "# Using the imputer on Cooling\n",
    "imputer = SimpleImputer(missing_values=None, strategy='most_frequent')\n",
    "df.Cooling = imputer.fit_transform(df['Cooling'].values.reshape(-1,1))[:, 0]\n",
    "\n",
    "# Double checking that there are no 'No Data' values\n",
    "display(df['Heating'].value_counts())\n",
    "display(df['Cooling'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train, test sets\n",
    "test_start, test_end = pd.Timestamp(2021, 2, 15), pd.Timestamp(2021, 3, 1)\n",
    "train_start = pd.Timestamp(2021, 1, 1) # you can change the start time stamp to include more training \n",
    "df['Sold On'] = pd.to_datetime(df['Sold On'], errors='coerce')\n",
    "train = df[(df['Sold On'] >= train_start) & (df['Sold On'] < test_start)]\n",
    "test = df[(df['Sold On'] >= test_start) & (df['Sold On'] < test_end)]\n",
    "train.shape, test.shape\n",
    "\n",
    "# Evaluate Model\n",
    "eval_model(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Results:\n",
    "Section 1.1 RMSLE: 0.2406 \\\n",
    "Section 3 RMSLE: 0.2414 \\\n",
    "Imputing data hardly affected the RMSLE, however I did notice that this section consistently results in an incredibly small increase in RMSLE compared to section 1.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Increasing Examples\n",
    "I want to increase the training dataset to include data from 2019 to 2021 instead of just 2021 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine df\n",
    "df = data[['Sold Price', 'Sold On', 'Type', 'Year built', 'Bedrooms', 'Bathrooms', \n",
    "           'Heating', 'Cooling', 'Parking']].copy()\n",
    "\n",
    "# Establish prediction target and Convert sold price to numerical data.\n",
    "c = 'Sold Price'\n",
    "if c in df.select_dtypes('object').columns:\n",
    "    df.loc[:,c] = np.log10(\n",
    "            pd.to_numeric(df[c].replace(r'[$,-]', '', regex=True)) + 1)\n",
    "\n",
    "# Removing outliers in sold price\n",
    "df = df[(df['Sold Price'] >= 4 ) & (df['Sold Price'] <= 8 )] # prices between 10^4 and 10^8\n",
    "\n",
    "# Get train, test sets\n",
    "test_start, test_end = pd.Timestamp(2021, 2, 15), pd.Timestamp(2021, 3, 1)\n",
    "train_start = pd.Timestamp(2019, 1, 1) # you can change the start time stamp to include more training \n",
    "df['Sold On'] = pd.to_datetime(df['Sold On'], errors='coerce')\n",
    "train = df[(df['Sold On'] >= train_start) & (df['Sold On'] < test_start)]\n",
    "test = df[(df['Sold On'] >= test_start) & (df['Sold On'] < test_end)]\n",
    "train.shape, test.shape\n",
    "\n",
    "# Evaluate Model\n",
    "eval_model(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Results:\n",
    "Section 1.1 RMSLE = 0.2406 \\\n",
    "Section 4 RMSLE = 0.2390 \\\n",
    "By increasing the dataset to include training data from 2019 and 2020 as well, the RMSLE decreases by just a little bit, about 0.0016 less. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXTRA:\n",
    "Trying to get the RMSLE as small as I possibly could.\n",
    "* Include Summary and Zip, noticable increase by adding this data.\n",
    "* Also adding other data such as High School Score and etc.\n",
    "* Binary encoding of Amenities included and Type\n",
    "* Impute year built, Last Sold Price, and High School Score\n",
    "* Increase examples for training data to 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placing this here so I don't have to rerun from the top.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def rmsle(y_hat, y):\n",
    "    # we already used log prices before, so we only need to compute RMSE\n",
    "    return sum((y_hat - y)**2 / len(y))**0.5\n",
    "\n",
    "def eval_model(train, test):\n",
    "    from autogluon.tabular import TabularPredictor\n",
    "    label = 'Sold Price'    \n",
    "    predictor = TabularPredictor(label=label).fit(train, hyperparameters={'GBM':{}})\n",
    "    preds = predictor.predict(test.drop(columns=[label]))\n",
    "    print(rmsle(preds, test[label]))\n",
    "\n",
    "data = pd.read_feather('house_sales.ftr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETEME\n",
    "def none_count(df, col_name):\n",
    "    display(df[col_name].value_counts())\n",
    "    display(df[col_name].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine df\n",
    "df = data[['Sold Price', 'Sold On', 'Type', 'Year built', 'Bedrooms', 'Bathrooms', \n",
    "           'Summary', 'Zip', 'Last Sold Price', 'High School Score', 'Amenities included']].copy()\n",
    "\n",
    "# Establish prediction target and Convert sold price to numerical data.\n",
    "c = 'Sold Price'\n",
    "if c in df.select_dtypes('object').columns:\n",
    "    df.loc[:,c] = np.log10(\n",
    "            pd.to_numeric(df[c].replace(r'[$,-]', '', regex=True)) + 1)\n",
    "    \n",
    "# Do same for Last Sold Price\n",
    "c = 'Last Sold Price'\n",
    "if c in df.select_dtypes('object').columns:\n",
    "    df.loc[:,c] = np.log10(\n",
    "            pd.to_numeric(df[c].replace(r'[$,-]', '', regex=True)) + 1)\n",
    "\n",
    "# Removing outliers in sold price\n",
    "df = df[(df['Sold Price'] >= 4 ) & (df['Sold Price'] <= 8 )] # prices between 10^4 and 10^8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "from sklearn.impute import SimpleImputer\n",
    "from numpy import nanmedian\n",
    "\n",
    "# Cleaning 'Year built' by imputing most frequent\n",
    "imputer = SimpleImputer(missing_values='No Data', strategy='most_frequent')\n",
    "df['Year built'] = imputer.fit_transform(df['Year built'].values.reshape(-1,1))[:, 0]\n",
    "\n",
    "# Cleaning Last Sold Price\n",
    "lsp_median = nanmedian(df['Last Sold Price'])\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=lsp_median)\n",
    "df['Last Sold Price'] = imputer.fit_transform(df['Last Sold Price'].values.reshape(-1,1))[:, 0]\n",
    "\n",
    "# Cleaning High School Score\n",
    "imputer = SimpleImputer(missing_values=None, strategy='most_frequent')\n",
    "df['High School Score'] = imputer.fit_transform(df['High School Score'].values.reshape(-1,1))[:, 0]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Encoding\n",
    "import category_encoders as ce\n",
    "\n",
    "# Create object of encoder, encode Amenities and Type\n",
    "ce_be = ce.BinaryEncoder(cols=['Amenities included', 'Type'])\n",
    "df = ce_be.fit_transform(df)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train, test sets\n",
    "test_start, test_end = pd.Timestamp(2021, 2, 15), pd.Timestamp(2021, 3, 1)\n",
    "train_start = pd.Timestamp(2020, 1, 1) # you can change the start time stamp to include more training \n",
    "df['Sold On'] = pd.to_datetime(df['Sold On'], errors='coerce')\n",
    "train = df[(df['Sold On'] >= train_start) & (df['Sold On'] < test_start)]\n",
    "test = df[(df['Sold On'] >= test_start) & (df['Sold On'] < test_end)]\n",
    "train.shape, test.shape\n",
    "\n",
    "# Evaluate Model\n",
    "eval_model(train, test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, I couldn't do it. It's hard!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw1_v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
